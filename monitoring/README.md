# üîç Monitoring - Schema & Quality Drift Detection

**Purpose:** Operational monitoring for schema evolution across Bronze, Silver, and Gold layers of the Medallion Architecture.

---


## üìÅ Structure

```
monitoring/
‚îú‚îÄ‚îÄ drift_monitoring_bronze.py    # Bronze layer schema drift detection
‚îú‚îÄ‚îÄ silver_drift_monitoring.py    # Silver layer drift monitoring (schema, quality, volume)
‚îú‚îÄ‚îÄ drift_monitoring_gold.py      # [Future] Gold layer monitoring
‚îî‚îÄ‚îÄ README.md                     # This file
```

**Notebooks:**
- [../notebooks/silver_drift_monitoring.ipynb](../notebooks/silver_drift_monitoring.ipynb) (Databricks-ready, executable)

---

## üéØ What is Schema Drift Monitoring?

Schema drift occurs when the structure of source data changes unexpectedly:
- ‚úÖ New columns added (e.g., `"Promotion_Flag"` appears in Price_Audit)
- ‚úÖ Columns removed (e.g., `"Auditor_Notes"` no longer in source)
- ‚úÖ Columns renamed (e.g., `"Observed_Price"` ‚Üí `"Current_Price"`)

**This monitoring detects these changes proactively without blocking data ingestion.**

---

## üèóÔ∏è Architecture

### Zero-Coupling Design (Opci√≥n A)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      DATA PIPELINE (notebooks/)                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Bronze Ingestion ‚Üí Silver Standardization ‚Üí Gold Analytics    ‚îÇ
‚îÇ         ‚Üì                    ‚Üì                      ‚Üì           ‚îÇ
‚îÇ    Writes Delta         Writes Delta          Writes Delta     ‚îÇ
‚îÇ         ‚Üì                    ‚Üì                      ‚Üì           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îÇ Delta History (_delta_log/) automatically tracks schemas
          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DELTA LAKE (Storage)                         ‚îÇ
‚îÇ  - Transaction logs with schema metadata (automatic)            ‚îÇ
‚îÇ  - DESCRIBE HISTORY provides version history                   ‚îÇ
‚îÇ  - No custom audit tables needed                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îÇ Reads Delta History (zero-compute, read-only)
          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  MONITORING (monitoring/)                       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Drift Detection ‚Üí Compare Delta Versions ‚Üí Generate Alerts    ‚îÇ
‚îÇ        ‚Üì                                                        ‚îÇ
‚îÇ   Delta Tables (bronze_schema_alerts, silver_drift_history)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Principle:** 
- ‚úÖ **Zero Coupling:** Pipelines don't know monitoring exists
- ‚úÖ **Single Source of Truth:** Delta History is authoritative
- ‚úÖ **No Custom Logging:** Delta automatically tracks schema changes

---


## üìä Silver Layer Monitoring

### Script: `silver_drift_monitoring.py`

**Schedule:** After each Silver write (post-write hook, see Silver notebook)
**Runtime:** ~1 minute (metadata-only, serverless-friendly)
**Cluster:** Serverless (same as Silver pipeline)

### What It Monitors

| Table | Drift Types | Alert Behavior |
|-------|------------|----------------|
| All Silver tables | Schema drift (new/missing/type changes), Quality drift (null/invalid rates), Volume drift (row count, key cardinality) | Alert on HIGH/MEDIUM/LOW severity, log in audit table |

### Severity Classification

| Severity | Condition | Action Required |
|----------|-----------|-----------------|
| **HIGH** üö® | Critical column missing, type change, >50% row count drop | URGENT: Review Silver logic, check upstream, notify consumers |
| **MEDIUM** ‚ö†Ô∏è | New column, moderate null/invalid increase, moderate volume change | WARNING: Review data quality, update documentation |
| **LOW** ‚ÑπÔ∏è | Minor changes, expected drift | INFO: Monitor, document |

### Output Table

**`silver_drift_history`** - Drift events with severity and details
```sql
SELECT * FROM workspace.default.silver_drift_history
ORDER BY timestamp DESC;
```

---

## üìä Bronze Layer Monitoring

### Notebook: `drift_monitoring_bronze.py`

**Schedule:** Daily at 3:05 AM (5 minutes after Bronze ingestion)  
**Runtime:** ~2-5 minutes (metadata operations only)  
**Cluster:** Serverless (same as Bronze ingestion)

### What It Monitors

| Table | Critical Columns | Alert Behavior |
|-------|------------------|----------------|
| `bronze_price_audit` | PDV_Code, Product_SKU, Audit_Date, Observed_Price | Alert on new OR removed columns |
| `bronze_sell_in` | Year, Product, PDV, Quantity, Amount | Alert on new OR removed columns |
| `bronze_master_pdv` | PDV_Code, PDV_Name | Alert on new columns only (dimension can evolve) |
| `bronze_master_products` | Product_SKU, Product_Name | Alert on new columns only |

### Severity Classification

| Severity | Condition | Action Required |
|----------|-----------|-----------------|
| **HIGH** üö® | Critical column removed | URGENT: Verify source change, update Silver validation, notify consumers |
| **MEDIUM** ‚ö†Ô∏è | Non-critical column removed | WARNING: Check Silver dependencies, verify intentional change |
| **LOW** ‚ÑπÔ∏è | New columns added | INFO: Document in data dictionary, consider Silver extension |

### Output Tables

**`bronze_schema_alerts`** - Drift alerts with severity (only table created by monitoring)
```sql
SELECT * FROM workspace.default.bronze_schema_alerts
WHERE layer = 'bronze' AND severity IN ('HIGH', 'MEDIUM')
ORDER BY detected_timestamp DESC;
```

---

## üöÄ How to Use

### Run Manually (Interactive)

1. Open Databricks workspace
2. Navigate to `/monitoring/drift_monitoring_bronze.py`
3. Click "Run All"
4. Review console output for detected drifts

### Run as Scheduled Job

**Databricks Workflow Configuration:**

```yaml
Job Name: Bronze_Pipeline_Daily

Tasks:
  1. bronze_ingestion
     Notebook: notebooks/01_bronze_ingestion.py
     Schedule: 3:00 AM daily
     
  2. drift_monitoring_bronze
     Notebook: monitoring/drift_monitoring_bronze.py
     Schedule: Depends on task 1 SUCCESS
     Timeout: 10 minutes
```

**Deploy via Databricks CLI:**
```bash
databricks jobs create --json-file .databricks/workflows/bronze_pipeline.json
```

---

## üìà Operational Queries

### Check Recent Alerts

```sql
SELECT 
    table_name,
    severity,
    new_columns,
    removed_columns,
    detected_timestamp
FROM workspace.default.bronze_schema_alerts
WHERE detected_timestamp >= current_date() - INTERVAL 7 DAYS
  AND layer = 'bronze'
ORDER BY severity DESC, detected_timestamp DESC;
```

### Tables Needing Attention

```sql
SELECT 
    table_name,
    COUNT(*) as unresolved_alerts,
    MAX(severity) as highest_severity
FROM workspace.default.bronze_schema_alerts
WHERE notified = false AND layer = 'bronze'
GROUP BY table_name
HAVING COUNT(*) > 0;
```

### Schema Evolution Timeline

```sql
SELECT 
    table_name,
    DATE(snapshot_timestamp) as date,
    column_count,
    COUNT(*) as snapshots_per_day
FROM workspace.default.bronze_schema_audit
WHERE layer = 'bronze'
GROUP BY table_name, DATE(snapshot_timestamp)
ORDER BY date DESC;
```

---

## üîß Configuration

### Adjust Lookback Period

Edit `drift_monitoring_bronze.py`:
```python
LOOKBACK_HOURS = 24  # Change to 48, 72, etc.
```

### Modify Critical Columns

Edit `BRONZE_TABLES_CONFIG` dictionary:
```python
"bronze_price_audit": {
    "critical_columns": ["PDV_Code", "Product_SKU", "Audit_Date", "Observed_Price", "NEW_CRITICAL_COL"],
    ...
}
```

### Enable Notifications (Future)

```python
# In drift_monitoring_bronze.py, uncomment:
if severity == "HIGH":
    send_slack_alert(message)
    send_email_alert(recipients)
```

---

## üéØ Design Decisions

### Why Separate from Data Pipeline?

**Problem if monitoring was inside Bronze notebook:**
- ‚ùå Schema issues could block data loading
- ‚ùå Violates "load-first" Bronze philosophy
- ‚ùå Increases ingestion latency

**SolutiOption A (Zero-Coupling)?

**Rejected Option B (Bronze logs snapshots):**
- ‚ùå Adds code to Bronze that isn't core responsibility
- ‚ùå Creates tight coupling between pipeline and monitoring
- ‚ùå Duplicates data Delta already has
- ‚ùå If Bronze logging fails, monitoring breaks

**Option A Benefits:**
- ‚úÖ **Zero Coupling:** Bronze doesn't know monitoring exists
- ‚úÖ **Single Source of Truth:** Delta History is authoritative
- ‚úÖ **No Extra Code:** Bronze stays clean (ingestion only)
- ‚úÖ **Self-Contained:** Monitoring reads Delta metadata directly

### Why Delta History Over Custom Tables?

Delta History already provides:
- Schema snapshots (via DESCRIBE TABLE + version)
- Transaction metadata (timestamp, user, operation)
- Zero-compute access (metadata-only)
- Automatic retention (transaction log lifecycle)

**No need for `bronze_schema_audit` table** - Delta does this natively!

### Why Zero-Compute Validation?

Uses `DESCRIBE HISTORY` + time travel instead of full table scans:
- ‚úÖ **Cost:** $0 (metadata-only operation)
- ‚úÖ **Speed:** Milliseconds vs seconds
- ‚úÖ **Serverless-friendly:** No data scanning

### Why Non-Blocking Architecture?

Bronze philosophy: **"Load first, validate later"**
- Data ingestion should never fail due to monitoring
- Drift detection is observability, not validation
- Monitoring failure doesn't stop pipeline
- Clean separation of concernsft_monitoring_bronze_guide.md)
- [Bronze Ingestion Notebook](../notebooks/01_bronze_ingestion.py)

---

## üîÆ Future Enhancements


### Phase 2: Silver & Gold Monitoring

```
monitoring/
‚îú‚îÄ‚îÄ drift_monitoring_bronze.py    ‚úÖ Implemented
‚îú‚îÄ‚îÄ silver_drift_monitoring.py    ‚úÖ Implemented
‚îî‚îÄ‚îÄ drift_monitoring_gold.py      üîú Planned
```

### Phase 3: Notification Integration

- Slack webhooks for HIGH severity
- Email alerts for critical column removal
- PagerDuty integration for production incidents

### Phase 4: Dashboard

Power BI/SQL dashboard showing:
- Drift frequency trends
- Tables by stability score
- Alert resolution time metrics
- Schema evolution heatmap

---

## ü§ù Contributing

**Adding New Tables to Monitor:**

1. Edit `BRONZE_TABLES_CONFIG` in `drift_monitoring_bronze.py`
2. Define critical columns
3. Set alert preferences
4. Test with manual run


**Adding New Monitoring Layers:**

1. Copy `drift_monitoring_bronze.py` ‚Üí `silver_drift_monitoring.py` (ya implementado)
2. Actualiza referencias de tablas y l√≥gica de drift seg√∫n la capa
3. Ajusta reglas de severidad y m√©tricas de calidad
4. A√±ade llamada post-write en el notebook correspondiente

---

**Author:** Diego Mayorga | diego.mayorgacapera@gmail.com  
**Last Updated:** 2025-12-31  
**Repository:** [github.com/DIEGO77M/BI_Market_Visibility](https://github.com/DIEGO77M/BI_Market_Visibility)
