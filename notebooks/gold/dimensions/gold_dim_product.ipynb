{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f31a35e",
   "metadata": {},
   "source": [
    "# Gold Dimension: Product (SCD Type 2)\n",
    "This notebook builds the Product dimension table in the Gold layer using SCD Type 2 logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d80c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, coalesce, current_date, sha2, concat_ws\n",
    "from pyspark.sql.types import StringType, DateType\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d536b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SCHEMA = \"default\"\n",
    "SILVER_MASTER_PRODUCTS = f\"{SCHEMA}.silver_master_products\"\n",
    "GOLD_DIM_PRODUCT = f\"{SCHEMA}.gold_dim_product\"\n",
    "\n",
    "print(\"Processing Gold Dimension: Product (SCD Type 2)\")\n",
    "print(f\"Source: {SILVER_MASTER_PRODUCTS}\")\n",
    "print(f\"Target: {GOLD_DIM_PRODUCT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a11817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Silver\n",
    "\n",
    "df_silver = spark.read.table(SILVER_MASTER_PRODUCTS)\n",
    "\n",
    "df_source = (\n",
    "    df_silver\n",
    "    .select(\n",
    "        col(\"product_code\").cast(StringType()).alias(\"product_code\"),\n",
    "        coalesce(col(\"product_name\"), col(\"product_code\")).alias(\"product_name\"),\n",
    "        coalesce(col(\"brand\"), lit(\"UNKNOWN\")).alias(\"brand\"),\n",
    "        coalesce(col(\"segment\"), lit(\"UNKNOWN\")).alias(\"segment\"),\n",
    "        coalesce(col(\"category\"), lit(\"UNKNOWN\")).alias(\"category\")\n",
    "    )\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "# Deterministic surrogate key (version-based)\n",
    "df_source = df_source.withColumn(\n",
    "    \"product_sk\",\n",
    "    sha2(\n",
    "        concat_ws(\n",
    "            \"||\",\n",
    "            col(\"product_code\"),\n",
    "            col(\"product_name\"),\n",
    "            col(\"brand\"),\n",
    "            col(\"segment\"),\n",
    "            col(\"category\")\n",
    "        ),\n",
    "        256\n",
    "    ).substr(1, 16)\n",
    ")\n",
    "df_source = (\n",
    "    df_source\n",
    "    .withColumn(\"valid_from\", current_date())\n",
    "    .withColumn(\"valid_to\", lit(\"9999-12-31\").cast(DateType()))\n",
    "    .withColumn(\"is_current\", lit(True))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c73bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial load or Incremental SCD Type 2\n",
    "if not spark.catalog.tableExists(GOLD_DIM_PRODUCT):\n",
    "    (\n",
    "        df_source\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .saveAsTable(GOLD_DIM_PRODUCT)\n",
    "    )\n",
    "    print(\"Initial load completed\")\n",
    "else:\n",
    "    delta_table = DeltaTable.forName(spark, GOLD_DIM_PRODUCT)\n",
    "    change_condition = \"\"\"\n",
    "        NOT (\n",
    "            target.product_name <=> source.product_name AND\n",
    "            target.brand        <=> source.brand        AND\n",
    "            target.segment      <=> source.segment      AND\n",
    "            target.category     <=> source.category\n",
    "        )\n",
    "    \"\"\"\n",
    "    (\n",
    "        delta_table.alias(\"target\")\n",
    "        .merge(\n",
    "            df_source.alias(\"source\"),\n",
    "            \"target.product_code = source.product_code AND target.is_current = true\"\n",
    "        )\n",
    "        .whenMatchedUpdate(\n",
    "            condition=change_condition,\n",
    "            set={\n",
    "                \"valid_to\": current_date(),\n",
    "                \"is_current\": lit(False)\n",
    "            }\n",
    "        )\n",
    "        .whenNotMatchedInsert(\n",
    "            values={\n",
    "                \"product_sk\": \"source.product_sk\",\n",
    "                \"product_code\": \"source.product_code\",\n",
    "                \"product_name\": \"source.product_name\",\n",
    "                \"brand\": \"source.brand\",\n",
    "                \"segment\": \"source.segment\",\n",
    "                \"category\": \"source.category\",\n",
    "                \"valid_from\": \"source.valid_from\",\n",
    "                \"valid_to\": \"source.valid_to\",\n",
    "                \"is_current\": \"source.is_current\"\n",
    "            }\n",
    "        )\n",
    "        .execute()\n",
    "    )\n",
    "    print(\"Incremental SCD2 merge completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35cf6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "spark.sql(f\"\"\"\n",
    "SELECT\n",
    "    COUNT(*) AS total_rows,\n",
    "    SUM(CASE WHEN is_current THEN 1 ELSE 0 END) AS current_rows\n",
    "FROM {GOLD_DIM_PRODUCT}\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
