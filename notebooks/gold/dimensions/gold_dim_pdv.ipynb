{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acec4a41",
   "metadata": {},
   "source": [
    "# Gold Dimension: PDV (SCD Type 2)\n",
    "This notebook builds the PDV (Point of Sale) dimension table in the Gold layer using SCD Type 2 logic.\n",
    "\n",
    "- Business key: code_eleader\n",
    "- PO code: code_po (informational)\n",
    "- SCD2 logic: pdv_sk, valid_from, valid_to, is_current\n",
    "- All columns mapped from Silver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, current_date, sha2, concat_ws\n",
    "from pyspark.sql.types import StringType, DateType\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8034cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"default\"\n",
    "SILVER_SCHEMA = \"default\"\n",
    "SILVER_MASTER_PDV = f\"{SILVER_SCHEMA}.silver_master_pdv\"\n",
    "GOLD_DIM_PDV = f\"{CATALOG}.{SCHEMA}.gold_dim_pdv\"\n",
    "\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA}\")\n",
    "\n",
    "print(\"Processing Gold Dimension: PDV (SCD Type 2)\")\n",
    "print(f\"Source: {SILVER_MASTER_PDV}\")\n",
    "print(f\"Target: {GOLD_DIM_PDV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Silver\n",
    "df_silver = spark.read.table(SILVER_MASTER_PDV)\n",
    "\n",
    "# Select and standardize columns for SCD2\n",
    "df_source = (\n",
    "    df_silver\n",
    "    .select(\n",
    "        col(\"code_eleader\").cast(StringType()).alias(\"code_eleader\"),\n",
    "        col(\"code_po\").cast(StringType()).alias(\"code_po\"),\n",
    "        col(\"store_name\"),\n",
    "        col(\"channel\"),\n",
    "        col(\"sub_channel\"),\n",
    "        col(\"chain\"),\n",
    "        col(\"neighborhood\"),\n",
    "        col(\"city\"),\n",
    "        col(\"parish\"),\n",
    "        col(\"country\"),\n",
    "        col(\"type_of_service\"),\n",
    "        col(\"status\"),\n",
    "        col(\"supervisor_code\"),\n",
    "        col(\"supervisor_name\"),\n",
    "        col(\"merchandiser_code\"),\n",
    "        col(\"merchandiser_name\"),\n",
    "        col(\"aditional_exhibitions\"),\n",
    "        col(\"commercial_activities\"),\n",
    "        col(\"planograms\"),\n",
    "        col(\"store_sap_code\"),\n",
    "        col(\"sales_rep\"),\n",
    "        col(\"latitude\"),\n",
    "        col(\"longitude\")\n",
    "    )\n",
    "    .distinct()\n",
    ")\n",
    "\n",
    "# Deterministic surrogate key (SCD2 hash)\n",
    "scd2_cols = [\n",
    "    \"code_eleader\", \"code_po\", \"store_name\", \"channel\", \"sub_channel\", \"chain\",\n",
    "    \"neighborhood\", \"city\", \"parish\", \"country\", \"type_of_service\", \"status\",\n",
    "    \"supervisor_code\", \"supervisor_name\", \"merchandiser_code\", \"merchandiser_name\",\n",
    "    \"aditional_exhibitions\", \"commercial_activities\", \"planograms\", \"store_sap_code\",\n",
    "    \"sales_rep\", \"latitude\", \"longitude\"\n",
    "]\n",
    "\n",
    "df_source = df_source.withColumn(\n",
    "    \"pdv_sk\",\n",
    "    sha2(concat_ws(\"||\", *[col(c).cast(StringType()) for c in scd2_cols]), 256).substr(1, 16)\n",
    ").withColumn(\"valid_from\", current_date()\n",
    ").withColumn(\"valid_to\", lit(\"9999-12-31\").cast(DateType())\n",
    ").withColumn(\"is_current\", lit(True))\n",
    "\n",
    "# Reorder columns\n",
    "final_cols = [\"pdv_sk\"] + scd2_cols + [\"valid_from\", \"valid_to\", \"is_current\"]\n",
    "df_source = df_source.select(final_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502581bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCD2 Merge Logic\n",
    "if not spark.catalog.tableExists(GOLD_DIM_PDV):\n",
    "    (\n",
    "        df_source\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .saveAsTable(GOLD_DIM_PDV)\n",
    "    )\n",
    "    print(\"Initial load completed\")\n",
    "else:\n",
    "    delta_table = DeltaTable.forName(spark, GOLD_DIM_PDV)\n",
    "    change_condition = \" OR \".join([f\"target.{c} <> source.{c}\" for c in scd2_cols])\n",
    "    (\n",
    "        delta_table.alias(\"target\")\n",
    "        .merge(\n",
    "            df_source.alias(\"source\"),\n",
    "            \"target.code_eleader = source.code_eleader AND target.is_current = true\"\n",
    "        )\n",
    "        .whenMatchedUpdate(\n",
    "            condition=change_condition,\n",
    "            set={\n",
    "                \"valid_to\": current_date(),\n",
    "                \"is_current\": lit(False)\n",
    "            }\n",
    "        )\n",
    "        .whenNotMatchedInsert(\n",
    "            values={c: f\"source.{c}\" for c in final_cols}\n",
    "        )\n",
    "        .execute()\n",
    "    )\n",
    "    print(\"Incremental SCD2 merge completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db20df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "spark.sql(f\"\"\"\n",
    "SELECT\n",
    "    COUNT(*) AS total_rows,\n",
    "    SUM(CASE WHEN is_current THEN 1 ELSE 0 END) AS current_rows\n",
    "FROM {GOLD_DIM_PDV}\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
